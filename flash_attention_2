{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U bitsandbytes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install flash-attn --no-build-isolation","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import multiprocessing\nimport subprocess\nfrom IPython import display\nimport time\n\ndef check_gpu_usage():\n    while True:\n        display.clear_output(wait=True)\n        print(subprocess.check_output('nvidia-smi').decode().strip())\n        time.sleep(2)\nrunner = multiprocessing.Process(target=check_gpu_usage)\nrunner.start()","metadata":{"execution":{"iopub.status.busy":"2024-08-16T20:20:34.844003Z","iopub.execute_input":"2024-08-16T20:20:34.844391Z","iopub.status.idle":"2024-08-16T20:20:34.871960Z","shell.execute_reply.started":"2024-08-16T20:20:34.844365Z","shell.execute_reply":"2024-08-16T20:20:34.870372Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Fri Aug 16 20:27:59 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   77C    P0             34W /   70W |    4427MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   76C    P0             32W /   70W |    5143MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"import gc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del model\ndel tokenizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\ntorch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\nimport torch\n\nmodel_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\ntokenizer = AutoTokenizer.from_pretrained(model_id)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T20:19:58.356618Z","iopub.execute_input":"2024-08-16T20:19:58.356933Z","iopub.status.idle":"2024-08-16T20:20:01.290828Z","shell.execute_reply.started":"2024-08-16T20:19:58.356905Z","shell.execute_reply":"2024-08-16T20:20:01.289776Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from transformers import BitsAndBytesConfig\n\nquantization_config = BitsAndBytesConfig(load_in_4bit=True)\n\nmodel = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", quantization_config=quantization_config,\n                                                attn_implementation=\"flash_attention_2\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T20:26:12.325752Z","iopub.execute_input":"2024-08-16T20:26:12.326378Z","iopub.status.idle":"2024-08-16T20:26:25.019375Z","shell.execute_reply.started":"2024-08-16T20:26:12.326345Z","shell.execute_reply":"2024-08-16T20:26:25.018590Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5050658621924313a3a09bb70046a9d1"}},"metadata":{}}]},{"cell_type":"code","source":"content = \"\"\"\nLondon (/ˈlʌndən/ LUN-dən)[6] is the capital and largest city[c] of both England and the United Kingdom, with a population of 8,866,180 in 2022.[2] The wider metropolitan area is the largest in Western Europe, with a population of 14.9 million.[7] London stands on the River Thames in southeast England, at the head of a 50-mile (80 km) estuary down to the North Sea, and has been a major settlement for nearly 2,000 years.[8] Its ancient core and financial centre, the City of London, was founded by the Romans as Londinium and has retained its medieval boundaries.[d][9] The City of Westminster, to the west of the City of London, has been the centuries-long host of the national government and parliament. London grew rapidly in the 19th century, becoming the world's largest city at the time. Since the 19th century,[10][11] the name \"London\" has referred to the metropolis around the City of London, historically split between the counties of Middlesex, Essex, Surrey, Kent, and Hertfordshire,[12] which since 1965 has largely comprised the administrative area of Greater London, governed by 33 local authorities and the Greater London Authority.[e][13]\n\nAs one of the world's major global cities,[14][15] London exerts a strong influence on world art, entertainment, fashion, commerce, finance, education, healthcare, media, science, technology, tourism, transport, and communications.[16][17] Despite a post-Brexit exodus of stock listings from the London Stock Exchange,[18] London remains Europe's most economically powerful city[19] and one of the world's major financial centres. It hosts Europe's largest concentration of higher education institutions,[20] some of which are the highest-ranked academic institutions in the world: Imperial College London in natural and applied sciences, the London School of Economics in social sciences, and the comprehensive University College London.[21][22] It is the most visited city in Europe and has the world's busiest city airport system.[23] The London Underground is the world's oldest rapid transit system.[24]\n\nLondon's diverse cultures encompass over 300 languages.[25] The 2023 population of Greater London of just under 10 million[26] made it Europe's third-most populous city,[27] accounting for 13.4% of the United Kingdom's population[28] and over 16% of England's population. The Greater London Built-up Area is the fourth-most populous in Europe, with about 9.8 million inhabitants as of 2011.[29][30] The London metropolitan area is the third-most populous in Europe, with about 14 million inhabitants as of 2016, making London a megacity.[f][31][32]\n\nFour World Heritage Sites are located in London: Kew Gardens; the Tower of London; the site featuring the Palace of Westminster, Church of St Margaret, and Westminster Abbey; and the historic settlement in Greenwich where the Royal Observatory defines the prime meridian (0° longitude) and Greenwich Mean Time.[33] Other landmarks include Buckingham Palace, the London Eye, Piccadilly Circus, St Paul's Cathedral, Tower Bridge, and Trafalgar Square. The city has the most museums, art galleries, libraries, and cultural venues in the UK, including the British Museum, National Gallery, Natural History Museum, Tate Modern, British Library, and numerous West End theatres.[34] Important sporting events held in London include the FA Cup Final, the Wimbledon Tennis Championships, and the London Marathon. It became the first city to host three Summer Olympic Games upon hosting the 2012 Summer Olympics.[35]\n\nToponymy\nMain article: Etymology of London\nLondon is an ancient name, attested in the first century AD, usually in the Latinised form Londinium.[36] Modern scientific analyses of the name must account for the origins of the different forms found in early sources: Latin (usually Londinium), Old English (usually Lunden), and Welsh (usually Llundein), with reference to the known developments over time of sounds in those different languages. It is agreed that the name came into these languages from Common Brythonic; recent work tends to reconstruct the lost Celtic form of the name as *Londonjon or something similar. This was then adapted into Latin as Londinium and borrowed into Old English.[37]\n\nUntil 1889, the name \"London\" applied officially only to the City of London, but since then it has also referred to the County of London and to Greater London.[38]\n\nHistory\nMain article: History of London\nFor a chronological guide, see Timeline of London.\nPrehistory\nIn 1993, remains of a Bronze Age bridge were found on the south foreshore upstream from Vauxhall Bridge.[39] Two of the timbers were radiocarbon dated to 1750–1285 BC.[39] In 2010, foundations of a large timber structure, dated to 4800–4500 BC,[40] were found on the Thames's south foreshore downstream from Vauxhall Bridge.[41] Both structures are on the south bank of the Thames, where the now-underground River Effra flows into the Thames.[41]\n\nRoman London\nMain article: Londinium\n\nReconstruction drawing of Londinium in 120 AD\n\nA surviving section of the 3rd-century London Wall behind Tower Hill\nDespite the evidence of scattered Brythonic settlements in the area, the first major settlement was founded by the Romans around 47 AD,[1] about four years after their invasion of 43 AD.[42] This only lasted until about 61 AD, when the Iceni tribe led by Queen Boudica stormed it and burnt it to the ground.[43]\n\nThe next planned incarnation of Londinium prospered, superseding Colchester as the principal city of the Roman province of Britannia in 100. At its height in the 2nd century, Roman London had a population of about 60,000.[44]\n\nAnglo-Saxon and Viking-period London\nWith the early 5th-century collapse of Roman rule, the walled city of Londinium was effectively abandoned, although Roman civilisation continued around St Martin-in-the-Fields until about 450.[45] From about 500, an Anglo-Saxon settlement known as Lundenwic developed slightly west of the old Roman city.[46] By about 680 the city had become a major port again, but there is little evidence of large-scale production. From the 820s repeated Viking assaults brought decline. Three are recorded; those in 851 and 886 succeeded, while the last, in 994, was rebuffed.[47]\n\nThe Vikings applied Danelaw over much of eastern and northern England, its boundary running roughly from London to Chester as an area of political and geographical control imposed by the Viking incursions formally agreed by the Danish warlord, Guthrum and the West Saxon king Alfred the Great in 886. The Anglo-Saxon Chronicle records that Alfred \"refounded\" London in 886. Archaeological research shows this involved abandonment of Lundenwic and a revival of life and trade within the old Roman walls. London then grew slowly until a dramatic increase in about 950.[48]\n\nBy the 11th century, London was clearly the largest town in England. Westminster Abbey, rebuilt in Romanesque style by King Edward the Confessor, was one of the grandest churches in Europe. Winchester had been the capital of Anglo-Saxon England, but from this time London became the main forum for foreign traders and the base for defence in time of war. In the view of Frank Stenton: \"It had the resources, and it was rapidly developing the dignity and the political self-consciousness appropriate to a national capital.\"[49]\n\nMiddle Ages\n\nWestminster Abbey, as seen in this painting (Canaletto, 1749), is a World Heritage Site and one of London's oldest and most important buildings.\nAfter winning the Battle of Hastings, William, Duke of Normandy was crowned King of England in newly completed Westminster Abbey on Christmas Day 1066.[50] William built the Tower of London, the first of many such in England rebuilt in stone in the south-eastern corner of the city, to intimidate the inhabitants.[51] In 1097, William II began building Westminster Hall, near the abbey. It became the basis of a new Palace of Westminster.[52]\n\nIn the 12th century, the institutions of central government, which had hitherto followed the royal English court around the country, grew in size and sophistication and became increasingly fixed, for most purposes at Westminster, although the royal treasury came to rest in the Tower. While the City of Westminster developed into a true governmental capital, its distinct neighbour, the City of London, remained England's largest city and principal commercial centre and flourished under its own unique administration, the Corporation of London. In 1100, its population was some 18,000; by 1300 it had grown to nearly 100,000.[53] With the Black Death in the mid-14th century, London lost nearly a third of its population.[54] London was the focus of the Peasants' Revolt in 1381.[55]\n\nLondon was a centre of England's Jewish population before their expulsion by Edward I in 1290. Violence against Jews occurred in 1190, when it was rumoured that the new king had ordered their massacre after they had presented themselves at his coronation.[56] In 1264 during the Second Barons' War, Simon de Montfort's rebels killed 500 Jews while attempting to seize records of debts.[57]\n\nEarly modern\n\nThe Lancastrian siege of London in 1471 is attacked by a Yorkist sally.\nDuring the Tudor period, the Reformation produced a gradual shift to Protestantism. Much of London property passed from church to private ownership, which accelerated trade and business in the city.[58] In 1475, the Hanseatic League set up a main trading base (kontor) of England in London, called the Stalhof or Steelyard. It remained until 1853, when the Hanseatic cities of Lübeck, Bremen and Hamburg sold the property to South Eastern Railway.[59] Woollen cloth was shipped undyed and undressed from 14th/15th century London to the nearby shores of the Low Countries.[60]\n\nYet English maritime enterprise hardly reached beyond the seas of north-west Europe. The commercial route to Italy and the Mediterranean was normally through Antwerp and over the Alps; any ships passing through the Strait of Gibraltar to or from England were likely to be Italian or Ragusan. The reopening of the Netherlands to English shipping in January 1565 spurred a burst of commercial activity.[61] The Royal Exchange was founded.[62] Mercantilism grew and monopoly traders such as the East India Company were founded as trade expanded to the New World. London became the main North Sea port, with migrants arriving from England and abroad. The population rose from about 50,000 in 1530 to about 225,000 in 1605.[58]\n\n\nMap of London in 1593. There is only one bridge across the Thames, but parts of Southwark on the south bank of the river have been developed.\nIn the 16th century, William Shakespeare and his contemporaries lived in London during English Renaissance theatre. Shakespeare's Globe Theatre was constructed in 1599 in Southwark. Stage performances came to a halt in London when Puritan authorities shut down the theatres in the 1640s.[63] The ban on theatre was lifted during the Restoration in 1660, and London's oldest operating theatre, Drury Lane, opened in 1663 in what is now the West End theatre district.[64]\n\nBy the end of the Tudor period in 1603, London was still compact. There was an assassination attempt on James I in Westminster, in the Gunpowder Plot of 5 November 1605.[65] In 1637, the government of Charles I attempted to reform administration in the London area. This called for the Corporation of the city to extend its jurisdiction and administration over expanding areas around the city. Fearing an attempt by the Crown to diminish the Liberties of London, coupled with a lack of interest in administering these additional areas or concern by city guilds of having to share power, caused the Corporation's \"The Great Refusal\", a decision which largely continues to account for the unique governmental status of the City.[66]\n\n\nThe Great Fire of London destroyed many parts of the city in 1666.\nIn the English Civil War, the majority of Londoners supported the Parliamentary cause. After an initial advance by the Royalists in 1642, culminating in the battles of Brentford and Turnham Green, London was surrounded by a defensive perimeter wall known as the Lines of Communication. The lines were built by up to 20,000 people, and were completed in under two months.[67] The fortifications failed their only test when the New Model Army entered London in 1647,[68] and they were levelled by Parliament the same year.[69] London was plagued by disease in the early 17th century,[70] culminating in the Great Plague of 1665–1666, which killed up to 100,000 people, or a fifth of the population.[70] The Great Fire of London broke out in 1666 in Pudding Lane in the city and quickly swept through the wooden buildings.[71] Rebuilding took over ten years and was supervised by polymath Robert Hooke.[72]\n\n\nSt Paul's Cathedral (painted by Edward Goodall in 1850) was completed in 1710\nIn 1710, Christopher Wren's masterpiece, St Paul's Cathedral, was completed, replacing its medieval predecessor that burned in the Great Fire of 1666. The dome of St Paul's dominated the London skyline for centuries, inspiring the artworks and writing of William Blake, with his 1789 poem \"Holy Thursday\" referring to ‘the high dome of Pauls'.[73] During the Georgian era, new districts such as Mayfair were formed in the west; new bridges over the Thames encouraged development in South London. In the east, the Port of London expanded downstream. London's development as an international financial centre matured for much of the 18th century.[74]\n\nIn 1762, George III acquired Buckingham House, which was enlarged over the next 75 years. During the 18th century, London was said to be dogged by crime,[75] and the Bow Street Runners were established in 1750 as a professional police force.[76] Epidemics during the 1720s and 30s saw most children born in the city die before reaching their fifth birthday.[77]\n\nCoffee-houses became a popular place to debate ideas, as growing literacy and development of the printing press made news widely available, with Fleet Street becoming the centre of the British press. The invasion of Amsterdam by Napoleonic armies led many financiers to relocate to London and the first London international issue was arranged in 1817. Around the same time, the Royal Navy became the world's leading war fleet, acting as a major deterrent to potential economic adversaries. Following a fire in 1838, the Royal Exchange was redesigned by William Tite and rebuilt in 1844. The repeal of the Corn Laws in 1846 was specifically aimed at weakening Dutch economic power. London then overtook Amsterdam as the leading international financial centre.[78]\n\nLate modern and contemporary\n\nThe Royal Exchange in 1886. It was founded in 1571 (with the present building rebuilt in 1844) as a centre of commerce for the City of London.\nWith the onset of the Industrial Revolution in Britain, an unprecedented growth in urbanisation took place, and the number of High Streets (the primary street for retail in Britain) rapidly grew.[79][80] London was the world's largest city from about 1831 to 1925, with a population density of 802 per acre (325 per hectare).[81] In addition to the growing number of stores selling goods, such as Harding, Howell & Co.—one of the first department stores—located on Pall Mall, the streets had scores of street sellers.[79] London's overcrowded conditions led to cholera epidemics, claiming 14,000 lives in 1848, and 6,000 in 1866.[82] Rising traffic congestion led to the creation of the London Underground, the world's first urban rail network.[83] The Metropolitan Board of Works oversaw infrastructure expansion in the capital and some surrounding counties; it was abolished in 1889 when the London County Council was created out of county areas surrounding the capital.[84]\n\nFrom the early years of the 20th century onwards, teashops were found on High Streets across London and the rest of Britain, with Lyons, who opened the first of their chain of teashops in Piccadilly in 1894, leading the way.[85] The tearooms, such as the Criterion in Piccadilly, became a popular meeting place for women from the suffrage movement.[86] The city was the target of many attacks during the suffragette bombing and arson campaign, between 1912 and 1914, which saw historic landmarks such as Westminster Abbey and St Paul's Cathedral bombed.[87]\n\n\nBritish volunteer recruits in London, August 1914, during World War I\n\nA bombed-out London street during the Blitz, World War II\nLondon was bombed by the Germans in the First World War, and during the Second World War, the Blitz and other bombings by the German Luftwaffe killed over 30,000 Londoners, destroying large tracts of housing and other buildings across the city.[88] The tomb of the Unknown Warrior, an unidentified member of the British armed forces killed during the First World War, was buried in Westminster Abbey on 11 November 1920.[89] The Cenotaph, located in Whitehall, was unveiled on the same day, and is the focal point for the National Service of Remembrance held annually on Remembrance Sunday, the closest Sunday to 11 November.[90]\n\nThe 1948 Summer Olympics were held at the original Wembley Stadium, while London was still recovering from the war.[91] From the 1940s, London became home to many immigrants, primarily from Commonwealth countries such as Jamaica, India, Bangladesh and Pakistan,[92] making London one of the most diverse cities in the world. In 1951, the Festival of Britain was held on the South Bank.[93] The Great Smog of 1952 led to the Clean Air Act 1956, which ended the \"pea soup fogs\" for which London had been notorious, and had earned it the nickname the \"Big Smoke\".[94]\n\nStarting mainly in the mid-1960s, London became a centre for worldwide youth culture, exemplified by the Swinging London sub-culture associated with the King's Road, Chelsea and Carnaby Street.[95] The role of trendsetter revived in the punk era.[96] In 1965 London's political boundaries were expanded in response to the growth of the urban area and a new Greater London Council was created.[97] During The Troubles in Northern Ireland, London was hit from 1973 by bomb attacks by the Provisional Irish Republican Army.[98] These attacks lasted for two decades, starting with the Old Bailey bombing.[98] Racial inequality was highlighted by the 1981 Brixton riot.[99]\n\nGreater London's population declined in the decades after the Second World War, from an estimated peak of 8.6 million in 1939 to around 6.8 million in the 1980s.[100] The principal ports for London moved downstream to Felixstowe and Tilbury, with the London Docklands area becoming a focus for regeneration, including the Canary Wharf development. This was born out of London's increasing role as an international financial centre in the 1980s.[101] Located about 2 miles (3 km) east of central London, the Thames Barrier was completed in the 1980s to protect London against tidal surges from the North Sea.[102]\n\nThe Greater London Council was abolished in 1986, leaving London with no central administration until 2000 and the creation of the Greater London Authority.[103] To mark the 21st century, the Millennium Dome, London Eye and Millennium Bridge were constructed.[104] On 6 July 2005 London was awarded the 2012 Summer Olympics, as the first city to stage the Olympic Games three times.[35] On 7 July 2005, three London Underground trains and a double-decker bus were bombed in a series of terrorist attacks.[98]\n\nIn 2008, Time named London alongside New York City and Hong Kong as Nylonkong, hailing them as the world's three most influential global cities.[105] In January 2015, Greater London's population was estimated to be 8.63 million, its highest since 1939.[106] During the Brexit referendum in 2016, the UK as a whole decided to leave the European Union, but most London constituencies voted for remaining.[107] However, Britain's exit from the EU in early 2020 only marginally weakened London's position as an international financial centre.[108]\n\nAdministration\nLocal government\nMain articles: Local government in London, History of local government in London, and List of heads of London government\n\nArms of the Corporation of the City of London[109]\nThe administration of London is formed of two tiers: a citywide, strategic tier and a local tier. Citywide administration is coordinated by the Greater London Authority (GLA), while local administration is carried out by 33 smaller authorities.[110] The GLA consists of two elected components: the mayor of London, who has executive powers, and the London Assembly, which scrutinises the mayor's decisions and can accept or reject the mayor's budget proposals each year. The GLA has responsibility for the majority of London's transport system through its functional arm Transport for London (TfL), it is responsible for overseeing the city's police and fire services, and also for setting a strategic vision for London on a range of issues.[111] The headquarters of the GLA is City Hall, Newham. The mayor since 2016 has been Sadiq Khan, the first Muslim mayor of a major Western capital.[112] The mayor's statutory planning strategy is published as the London Plan, which was most recently revised in 2011.[113]\n\nThe local authorities are the councils of the 32 London boroughs and the City of London Corporation.[114] They are responsible for most local services, such as local planning, schools, libraries, leisure and recreation, social services, local roads and refuse collection.[115] Certain functions, such as waste management, are provided through joint arrangements. In 2009–2010 the combined revenue expenditure by London councils and the GLA amounted to just over £22 billion (£14.7 billion for the boroughs and £7.4 billion for the GLA).[116]\n\nThe London Fire Brigade is the statutory fire and rescue service for Greater London, run by the London Fire and Emergency Planning Authority. It is the third largest fire service in the world.[117] National Health Service ambulance services are provided by the London Ambulance Service (LAS) NHS Trust, the largest free-at-the-point-of-use emergency ambulance service in the world.[118] The London Air Ambulance charity operates in conjunction with the LAS where required. Her Majesty's Coastguard and the Royal National Lifeboat Institution operate on the River Thames, which is under the jurisdiction of the Port of London Authority from Teddington Lock to the sea.[119]\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-08-16T20:26:25.021027Z","iopub.execute_input":"2024-08-16T20:26:25.021318Z","iopub.status.idle":"2024-08-16T20:26:25.046659Z","shell.execute_reply.started":"2024-08-16T20:26:25.021292Z","shell.execute_reply":"2024-08-16T20:26:25.045721Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"prompts = \"\"\"summary the text /n text:{} \"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-08-16T20:26:25.047959Z","iopub.execute_input":"2024-08-16T20:26:25.048649Z","iopub.status.idle":"2024-08-16T20:26:25.057751Z","shell.execute_reply.started":"2024-08-16T20:26:25.048624Z","shell.execute_reply":"2024-08-16T20:26:25.056989Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"conversation = [{\"role\": \"user\", \"content\": prompts.format(content)}]\n\n# render the tool use prompt as a string:\nprompt = tokenizer.apply_chat_template(\n            conversation,\n            tokenize=False,\n            add_generation_prompt=True,\n)\n\ninputs = tokenizer(prompt, return_tensors=\"pt\")","metadata":{"execution":{"iopub.status.busy":"2024-08-16T20:26:25.059502Z","iopub.execute_input":"2024-08-16T20:26:25.059761Z","iopub.status.idle":"2024-08-16T20:26:25.078029Z","shell.execute_reply.started":"2024-08-16T20:26:25.059738Z","shell.execute_reply":"2024-08-16T20:26:25.077344Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"inputs[0]","metadata":{"execution":{"iopub.status.busy":"2024-08-16T20:26:25.078961Z","iopub.execute_input":"2024-08-16T20:26:25.079220Z","iopub.status.idle":"2024-08-16T20:26:25.084529Z","shell.execute_reply.started":"2024-08-16T20:26:25.079197Z","shell.execute_reply":"2024-08-16T20:26:25.083736Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"Encoding(num_tokens=5964, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"},"metadata":{}}]},{"cell_type":"markdown","source":"Beam search","metadata":{"execution":{"iopub.status.busy":"2024-08-16T18:55:09.727304Z","iopub.execute_input":"2024-08-16T18:55:09.727625Z","iopub.status.idle":"2024-08-16T18:55:09.733005Z","shell.execute_reply.started":"2024-08-16T18:55:09.727600Z","shell.execute_reply":"2024-08-16T18:55:09.731734Z"}}},{"cell_type":"code","source":"%%time\noutputs = model.generate(**inputs, max_new_tokens =2000)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T20:26:25.085677Z","iopub.execute_input":"2024-08-16T20:26:25.085937Z","iopub.status.idle":"2024-08-16T20:26:25.541890Z","shell.execute_reply.started":"2024-08-16T20:26:25.085914Z","shell.execute_reply":"2024-08-16T20:26:25.540999Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1797: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n  warnings.warn(\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","File \u001b[0;32m<timed exec>:1\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1914\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1906\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1907\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1908\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1909\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1910\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1911\u001b[0m     )\n\u001b[1;32m   1913\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 1914\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1922\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1923\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   1926\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1927\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1928\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   1929\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[1;32m   1930\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1931\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:2651\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2648\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2650\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2651\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2652\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2654\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2655\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2656\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2659\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:1200\u001b[0m, in \u001b[0;36mMistralForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1197\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1199\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1200\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1213\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1214\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:976\u001b[0m, in \u001b[0;36mMistralModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    965\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    966\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    967\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    973\u001b[0m         cache_position,\n\u001b[1;32m    974\u001b[0m     )\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 976\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:718\u001b[0m, in \u001b[0;36mMistralDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    715\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    717\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 718\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    727\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    729\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:414\u001b[0m, in \u001b[0;36mMistralFlashAttention2.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[1;32m    411\u001b[0m key_states \u001b[38;5;241m=\u001b[39m key_states\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    412\u001b[0m value_states \u001b[38;5;241m=\u001b[39m value_states\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 414\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flash_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_sliding_windows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_sliding_windows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mreshape(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    425\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mo_proj(attn_output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:511\u001b[0m, in \u001b[0;36mMistralFlashAttention2._flash_attention_forward\u001b[0;34m(self, query_states, key_states, value_states, attention_mask, query_length, dropout, softmax_scale, use_sliding_windows)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_sliding_windows:\n\u001b[0;32m--> 511\u001b[0m         attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mflash_attn_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m            \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m            \u001b[49m\u001b[43msoftmax_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msoftmax_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcausal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    520\u001b[0m         attn_output \u001b[38;5;241m=\u001b[39m flash_attn_func(\n\u001b[1;32m    521\u001b[0m             query_states,\n\u001b[1;32m    522\u001b[0m             key_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    527\u001b[0m             window_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39msliding_window, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39msliding_window),\n\u001b[1;32m    528\u001b[0m         )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py:880\u001b[0m, in \u001b[0;36mflash_attn_func\u001b[0;34m(q, k, v, dropout_p, softmax_scale, causal, window_size, softcap, alibi_slopes, deterministic, return_attn_probs)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflash_attn_func\u001b[39m(\n\u001b[1;32m    820\u001b[0m     q,\n\u001b[1;32m    821\u001b[0m     k,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    830\u001b[0m     return_attn_probs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    831\u001b[0m ):\n\u001b[1;32m    832\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"dropout_p should be set to 0.0 during evaluation\u001b[39;00m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;124;03m    Supports multi-query and grouped-query attention (MQA/GQA) by passing in KV with fewer heads\u001b[39;00m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;124;03m    than Q. Note that the number of heads in Q must be divisible by the number of heads in KV.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;124;03m            pattern (negative means that location was dropped, nonnegative means it was kept).\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 880\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFlashAttnFunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43msoftmax_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcausal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43msoftcap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43malibi_slopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attn_probs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/function.py:539\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    538\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    543\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    544\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    545\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    547\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py:546\u001b[0m, in \u001b[0;36mFlashAttnFunc.forward\u001b[0;34m(ctx, q, k, v, dropout_p, softmax_scale, causal, window_size, softcap, alibi_slopes, deterministic, return_softmax)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m softmax_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    545\u001b[0m     softmax_scale \u001b[38;5;241m=\u001b[39m q\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m--> 546\u001b[0m out, q, k, v, out_padded, softmax_lse, S_dmask, rng_state \u001b[38;5;241m=\u001b[39m \u001b[43m_flash_attn_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m    \u001b[49m\u001b[43msoftmax_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcausal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43msoftcap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msoftcap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43malibi_slopes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malibi_slopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_softmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_softmax\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m ctx\u001b[38;5;241m.\u001b[39msave_for_backward(q, k, v, out_padded, softmax_lse, rng_state)\n\u001b[1;32m    559\u001b[0m ctx\u001b[38;5;241m.\u001b[39mdropout_p \u001b[38;5;241m=\u001b[39m dropout_p\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py:52\u001b[0m, in \u001b[0;36m_flash_attn_forward\u001b[0;34m(q, k, v, dropout_p, softmax_scale, causal, window_size, softcap, alibi_slopes, return_softmax)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_flash_attn_forward\u001b[39m(\n\u001b[1;32m     49\u001b[0m     q, k, v, dropout_p, softmax_scale, causal, window_size, softcap, alibi_slopes, return_softmax\n\u001b[1;32m     50\u001b[0m ):\n\u001b[1;32m     51\u001b[0m     q, k, v \u001b[38;5;241m=\u001b[39m [maybe_contiguous(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m (q, k, v)]\n\u001b[0;32m---> 52\u001b[0m     out, q, k, v, out_padded, softmax_lse, S_dmask, rng_state \u001b[38;5;241m=\u001b[39m \u001b[43mflash_attn_cuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfwd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43malibi_slopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43msoftmax_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcausal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43msoftcap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_softmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out, q, k, v, out_padded, softmax_lse, S_dmask, rng_state\n","\u001b[0;31mRuntimeError\u001b[0m: FlashAttention only supports Ampere GPUs or newer.\nException raised from mha_fwd at /home/runner/work/flash-attention/flash-attention/csrc/flash_attn/flash_api.cpp:364 (most recent call first):\nframe #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x6c (0x7c906093151c in /opt/conda/lib/python3.10/site-packages/torch/lib/libc10.so)\nframe #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x84 (0x7c90608e6b04 in /opt/conda/lib/python3.10/site-packages/torch/lib/libc10.so)\nframe #2: mha_fwd(at::Tensor&, at::Tensor const&, at::Tensor const&, c10::optional<at::Tensor>&, c10::optional<at::Tensor>&, float, float, bool, int, int, float, bool, c10::optional<at::Generator>) + 0xfff (0x7c8feba4a8bf in /opt/conda/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so)\nframe #3: <unknown function> + 0x1b3fc8 (0x7c8feba67fc8 in /opt/conda/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so)\nframe #4: <unknown function> + 0x1b0659 (0x7c8feba64659 in /opt/conda/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so)\nframe #5: <unknown function> + 0x144446 (0x5c40e0844446 in /opt/conda/bin/python3.10)\nframe #6: _PyObject_MakeTpCall + 0x26b (0x5c40e083d97b in /opt/conda/bin/python3.10)\nframe #7: _PyEval_EvalFrameDefault + 0x54b6 (0x5c40e08398c6 in /opt/conda/bin/python3.10)\nframe #8: _PyFunction_Vectorcall + 0x6c (0x5c40e08448cc in /opt/conda/bin/python3.10)\nframe #9: _PyEval_EvalFrameDefault + 0x13cc (0x5c40e08357dc in /opt/conda/bin/python3.10)\nframe #10: _PyFunction_Vectorcall + 0x6c (0x5c40e08448cc in /opt/conda/bin/python3.10)\nframe #11: THPFunction_apply(_object*, _object*) + 0x1048 (0x7c90a0df50b8 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_python.so)\nframe #12: <unknown function> + 0x144468 (0x5c40e0844468 in /opt/conda/bin/python3.10)\nframe #13: PyObject_Call + 0x207 (0x5c40e0850ee7 in /opt/conda/bin/python3.10)\nframe #14: _PyEval_EvalFrameDefault + 0x5d5d (0x5c40e083a16d in /opt/conda/bin/python3.10)\nframe #15: <unknown function> + 0x150402 (0x5c40e0850402 in /opt/conda/bin/python3.10)\nframe #16: _PyEval_EvalFrameDefault + 0x4c12 (0x5c40e0839022 in /opt/conda/bin/python3.10)\nframe #17: _PyFunction_Vectorcall + 0x6c (0x5c40e08448cc in /opt/conda/bin/python3.10)\nframe #18: _PyEval_EvalFrameDefault + 0x13cc (0x5c40e08357dc in /opt/conda/bin/python3.10)\nframe #19: <unknown function> + 0x150402 (0x5c40e0850402 in /opt/conda/bin/python3.10)\nframe #20: _PyEval_EvalFrameDefault + 0x13cc (0x5c40e08357dc in /opt/conda/bin/python3.10)\nframe #21: <unknown function> + 0x150402 (0x5c40e0850402 in /opt/conda/bin/python3.10)\nframe #22: PyObject_Call + 0xbc (0x5c40e0850d9c in /opt/conda/bin/python3.10)\nframe #23: _PyEval_EvalFrameDefault + 0x2d84 (0x5c40e0837194 in /opt/conda/bin/python3.10)\nframe #24: _PyFunction_Vectorcall + 0x6c (0x5c40e08448cc in /opt/conda/bin/python3.10)\nframe #25: <unknown function> + 0x1d5e52 (0x5c40e08d5e52 in /opt/conda/bin/python3.10)\nframe #26: <unknown function> + 0x20a2e7 (0x5c40e090a2e7 in /opt/conda/bin/python3.10)\nframe #27: PyObject_Call + 0xbc (0x5c40e0850d9c in /opt/conda/bin/python3.10)\nframe #28: _PyEval_EvalFrameDefault + 0x2d84 (0x5c40e0837194 in /opt/conda/bin/python3.10)\nframe #29: <unknown function> + 0x150402 (0x5c40e0850402 in /opt/conda/bin/python3.10)\nframe #30: PyObject_Call + 0xbc (0x5c40e0850d9c in /opt/conda/bin/python3.10)\nframe #31: _PyEval_EvalFrameDefault + 0x2d84 (0x5c40e0837194 in /opt/conda/bin/python3.10)\nframe #32: _PyFunction_Vectorcall + 0x6c (0x5c40e08448cc in /opt/conda/bin/python3.10)\nframe #33: _PyObject_FastCallDictTstate + 0x187 (0x5c40e083cf17 in /opt/conda/bin/python3.10)\nframe #34: _PyObject_Call_Prepend + 0x69 (0x5c40e084eab9 in /opt/conda/bin/python3.10)\nframe #35: <unknown function> + 0x210db9 (0x5c40e0910db9 in /opt/conda/bin/python3.10)\nframe #36: _PyObject_MakeTpCall + 0x26b (0x5c40e083d97b in /opt/conda/bin/python3.10)\nframe #37: _PyEval_EvalFrameDefault + 0x56e0 (0x5c40e0839af0 in /opt/conda/bin/python3.10)\nframe #38: <unknown function> + 0x150402 (0x5c40e0850402 in /opt/conda/bin/python3.10)\nframe #39: PyObject_Call + 0xbc (0x5c40e0850d9c in /opt/conda/bin/python3.10)\nframe #40: _PyEval_EvalFrameDefault + 0x2d84 (0x5c40e0837194 in /opt/conda/bin/python3.10)\nframe #41: _PyFunction_Vectorcall + 0x6c (0x5c40e08448cc in /opt/conda/bin/python3.10)\nframe #42: <unknown function> + 0x1d5e52 (0x5c40e08d5e52 in /opt/conda/bin/python3.10)\nframe #43: <unknown function> + 0x20a2e7 (0x5c40e090a2e7 in /opt/conda/bin/python3.10)\nframe #44: PyObject_Call + 0xbc (0x5c40e0850d9c in /opt/conda/bin/python3.10)\nframe #45: _PyEval_EvalFrameDefault + 0x2d84 (0x5c40e0837194 in /opt/conda/bin/python3.10)\nframe #46: <unknown function> + 0x150402 (0x5c40e0850402 in /opt/conda/bin/python3.10)\nframe #47: PyObject_Call + 0xbc (0x5c40e0850d9c in /opt/conda/bin/python3.10)\nframe #48: _PyEval_EvalFrameDefault + 0x2d84 (0x5c40e0837194 in /opt/conda/bin/python3.10)\nframe #49: _PyFunction_Vectorcall + 0x6c (0x5c40e08448cc in /opt/conda/bin/python3.10)\nframe #50: _PyObject_FastCallDictTstate + 0x187 (0x5c40e083cf17 in /opt/conda/bin/python3.10)\nframe #51: _PyObject_Call_Prepend + 0x69 (0x5c40e084eab9 in /opt/conda/bin/python3.10)\nframe #52: <unknown function> + 0x210db9 (0x5c40e0910db9 in /opt/conda/bin/python3.10)\nframe #53: _PyObject_MakeTpCall + 0x26b (0x5c40e083d97b in /opt/conda/bin/python3.10)\nframe #54: _PyEval_EvalFrameDefault + 0x56e0 (0x5c40e0839af0 in /opt/conda/bin/python3.10)\nframe #55: <unknown function> + 0x150402 (0x5c40e0850402 in /opt/conda/bin/python3.10)\nframe #56: PyObject_Call + 0xbc (0x5c40e0850d9c in /opt/conda/bin/python3.10)\nframe #57: _PyEval_EvalFrameDefault + 0x2d84 (0x5c40e0837194 in /opt/conda/bin/python3.10)\nframe #58: <unknown function> + 0x150402 (0x5c40e0850402 in /opt/conda/bin/python3.10)\nframe #59: PyObject_Call + 0xbc (0x5c40e0850d9c in /opt/conda/bin/python3.10)\nframe #60: _PyEval_EvalFrameDefault + 0x2d84 (0x5c40e0837194 in /opt/conda/bin/python3.10)\nframe #61: _PyFunction_Vectorcall + 0x6c (0x5c40e08448cc in /opt/conda/bin/python3.10)\nframe #62: _PyObject_FastCallDictTstate + 0x187 (0x5c40e083cf17 in /opt/conda/bin/python3.10)\nframe #63: _PyObject_Call_Prepend + 0x69 (0x5c40e084eab9 in /opt/conda/bin/python3.10)\n"],"ename":"RuntimeError","evalue":"FlashAttention only supports Ampere GPUs or newer.\nException raised from mha_fwd at /home/runner/work/flash-attention/flash-attention/csrc/flash_attn/flash_api.cpp:364 (most recent call first):\nframe #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x6c (0x7c906093151c in /opt/conda/lib/python3.10/site-packages/torch/lib/libc10.so)\nframe #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x84 (0x7c90608e6b04 in /opt/conda/lib/python3.10/site-packages/torch/lib/libc10.so)\nframe #2: mha_fwd(at::Tensor&, at::Tensor const&, at::Tensor const&, c10::optional<at::Tensor>&, c10::optional<at::Tensor>&, float, float, bool, int, int, float, bool, c10::optional<at::Generator>) + 0xfff (0x7c8feba4a8bf in /opt/conda/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so)\nframe #3: <unknown function> + 0x1b3fc8 (0x7c8feba67fc8 in /opt/conda/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so)\nframe #4: <unknown function> + 0x1b0659 (0x7c8feba64659 in /opt/conda/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so)\nframe #5: <unknown function> + 0x144446 (0x5c40e0844446 in /opt/conda/bin/python3.10)\nframe #6: _PyObject_MakeTpCall + 0x26b (0x5c40e083d97b in /opt/conda/bin/python3.10)\nframe #7: _PyEval_EvalFrameDefault + 0x54b6 (0x5c40e08398c6 in /opt/conda/bin/python3.10)\nframe #8: _PyFunction_Vectorcall + 0x6c (0x5c40e08448cc in /opt/conda/bin/python3.10)\nframe #9: _PyEval_EvalFrameDefault + 0x13cc (0x5c40e08357dc in /opt/conda/bin/python3.10)\nframe #10: _PyFunction_Vectorcall + 0x6c (0x5c40e08448cc in /opt/conda/bin/python3.10)\nframe #11: THPFunction_apply(_object*, _object*) + 0x1048 (0x7c90a0df50b8 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_python.so)\nframe #12: <unknown function> + 0x144468 (0x5c40e0844468 in /opt/conda/bin/python3.10)\nframe #13: PyObject_Call + 0x207 (0x5c40e0850ee7 in /opt/conda/bin/python3.10)\nframe #14: _PyEval_EvalFrameDefault + 0x5d5d (0x5c40e083a16d in /opt/conda/bin/python3.10)\nframe #15: <unknown function> + 0x150402 (0x5c40e0850402 in /opt/conda/bin/python3.10)\nframe #16: _PyEval_EvalFrameDefault + 0x4c12 (0x5c40e0839022 in /opt/conda/bin/python3.10)\nframe #17: _PyFunction_Vectorcall + 0x6c (0x5c40e08448cc in /opt/conda/bin/python3.10)\nframe #18: _PyEval_EvalFrameDefault + 0x13cc (0x5c40e08357dc in /opt/conda/bin/python3.10)\nframe #19: <unknown function> + 0x150402 (0x5c40e0850402 in /opt/conda/bin/python3.10)\nframe #20: _PyEval_EvalFrameDefault + 0x13cc (0x5c40e08357dc in /opt/conda/bin/python3.10)\nframe #21: <unknown function> + 0x150402 (0x5c40e0850402 in /opt/conda/bin/python3.10)\nframe #22: PyObject_Call + 0xbc (0x5c40e0850d9c in /opt/conda/bin/python3.10)\nframe #23: _PyEval_EvalFrameDefault + 0x2d84 (0x5c40e0837194 in /opt/conda/bin/python3.10)\nframe #24: _PyFunction_Vectorcall + 0x6c (0x5c40e08448cc in /opt/conda/bin/python3.10)\nframe #25: <unknown function> + 0x1d5e52 (0x5c40e08d5e52 in /opt/conda/bin/python3.10)\nframe #26: <unknown function> + 0x20a2e7 (0x5c40e090a2e7 in /opt/conda/bin/python3.10)\nframe #27: PyObject_Call + 0xbc (0x5c40e0850d9c in /opt/conda/bin/python3.10)\nframe #28: _PyEval_EvalFrameDefault + 0x2d84 (0x5c40e0837194 in /opt/conda/bin/python3.10)\nframe #29: <unknown function> + 0x150402 (0x5c40e0850402 in /opt/conda/bin/python3.10)\nframe #30: PyObject_Call + 0xbc (0x5c40e0850d9c in /opt/conda/bin/python3.10)\nframe #31: _PyEval_EvalFrameDefault + 0x2d84 (0x5c40e0837194 in /opt/conda/bin/python3.10)\nframe #32: _PyFunction_Vectorcall + 0x6c (0x5c40e08448cc in /opt/conda/bin/python3.10)\nframe #33: _PyObject_FastCallDictTstate + 0x187 (0x5c40e083cf17 in /opt/conda/bin/python3.10)\nframe #34: _PyObject_Call_Prepend + 0x69 (0x5c40e084eab9 in /opt/conda/bin/python3.10)\nframe #35: <unknown function> + 0x210db9 (0x5c40e0910db9 in /opt/conda/bin/python3.10)\nframe #36: _PyObject_MakeTpCall + 0x26b (0x5c40e083d97b in /opt/conda/bin/python3.10)\nframe #37: _PyEval_EvalFrameDefault + 0x56e0 (0x5c40e0839af0 in /opt/conda/bin/python3.10)\nframe #38: <unknown function> + 0x150402 (0x5c40e0850402 in /opt/conda/bin/python3.10)\nframe #39: PyObject_Call + 0xbc (0x5c40e0850d9c in /opt/conda/bin/python3.10)\nframe #40: _PyEval_EvalFrameDefault + 0x2d84 (0x5c40e0837194 in /opt/conda/bin/python3.10)\nframe #41: _PyFunction_Vectorcall + 0x6c (0x5c40e08448cc in /opt/conda/bin/python3.10)\nframe #42: <unknown function> + 0x1d5e52 (0x5c40e08d5e52 in /opt/conda/bin/python3.10)\nframe #43: <unknown function> + 0x20a2e7 (0x5c40e090a2e7 in /opt/conda/bin/python3.10)\nframe #44: PyObject_Call + 0xbc (0x5c40e0850d9c in /opt/conda/bin/python3.10)\nframe #45: _PyEval_EvalFrameDefault + 0x2d84 (0x5c40e0837194 in /opt/conda/bin/python3.10)\nframe #46: <unknown function> + 0x150402 (0x5c40e0850402 in /opt/conda/bin/python3.10)\nframe #47: PyObject_Call + 0xbc (0x5c40e0850d9c in /opt/conda/bin/python3.10)\nframe #48: _PyEval_EvalFrameDefault + 0x2d84 (0x5c40e0837194 in /opt/conda/bin/python3.10)\nframe #49: _PyFunction_Vectorcall + 0x6c (0x5c40e08448cc in /opt/conda/bin/python3.10)\nframe #50: _PyObject_FastCallDictTstate + 0x187 (0x5c40e083cf17 in /opt/conda/bin/python3.10)\nframe #51: _PyObject_Call_Prepend + 0x69 (0x5c40e084eab9 in /opt/conda/bin/python3.10)\nframe #52: <unknown function> + 0x210db9 (0x5c40e0910db9 in /opt/conda/bin/python3.10)\nframe #53: _PyObject_MakeTpCall + 0x26b (0x5c40e083d97b in /opt/conda/bin/python3.10)\nframe #54: _PyEval_EvalFrameDefault + 0x56e0 (0x5c40e0839af0 in /opt/conda/bin/python3.10)\nframe #55: <unknown function> + 0x150402 (0x5c40e0850402 in /opt/conda/bin/python3.10)\nframe #56: PyObject_Call + 0xbc (0x5c40e0850d9c in /opt/conda/bin/python3.10)\nframe #57: _PyEval_EvalFrameDefault + 0x2d84 (0x5c40e0837194 in /opt/conda/bin/python3.10)\nframe #58: <unknown function> + 0x150402 (0x5c40e0850402 in /opt/conda/bin/python3.10)\nframe #59: PyObject_Call + 0xbc (0x5c40e0850d9c in /opt/conda/bin/python3.10)\nframe #60: _PyEval_EvalFrameDefault + 0x2d84 (0x5c40e0837194 in /opt/conda/bin/python3.10)\nframe #61: _PyFunction_Vectorcall + 0x6c (0x5c40e08448cc in /opt/conda/bin/python3.10)\nframe #62: _PyObject_FastCallDictTstate + 0x187 (0x5c40e083cf17 in /opt/conda/bin/python3.10)\nframe #63: _PyObject_Call_Prepend + 0x69 (0x5c40e084eab9 in /opt/conda/bin/python3.10)\n","output_type":"error"}]},{"cell_type":"code","source":"%%time\noutputs = model.generate(**inputs, max_new_tokens =2000, num_beams = 2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\noutputs = model.generate(**inputs, max_new_tokens =2000, num_beams = 3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tokenizer.decode(outputs[0], skip_special_tokens=False))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}